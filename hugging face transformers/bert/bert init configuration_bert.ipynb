{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from typing import TYPE_CHECKING # 类型检查\nfrom transformers.utils import _LazyModule\nfrom transformers.utils.import_utils import define_import_structure\nif TYPE_CHECKING: # 静态检查工具检测时\n    from transformers.models.bert.modeling_bert import *\n    from transformers.models.bert.modeling_flax_bert import *\n    from transformers.models.bert.modeling_tf_bert import *\n    from transformers.models.bert.tokenization_bert import *\n    from transformers.models.bert.tokenization_bert_fast import *\n    from transformers.models.bert.tokenization_bert_tf import *\nelse: # 否则,懒加载\n    import sys\n    _file = globals()[\"__file__\"]\n    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import OrderedDict # 有序字典\nfrom typing import Mapping\nfrom transformers.configuration_utils import PretrainedConfig\nfrom transformers.onnx import OnnxConfig\nfrom transformers.utils import logging\n\nlogger = logging.get_logger(__name__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:05:57.934714Z","iopub.execute_input":"2025-05-28T09:05:57.935512Z","iopub.status.idle":"2025-05-28T09:05:58.055987Z","shell.execute_reply.started":"2025-05-28T09:05:57.935480Z","shell.execute_reply":"2025-05-28T09:05:58.055463Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class BertConfig(PretrainedConfig):\n    \"\"\"\n    Examples:\n\n    ```python\n    >>> from transformers import BertConfig, BertModel\n\n    >>> # Initializing a BERT google-bert/bert-base-uncased style configuration\n    >>> configuration = BertConfig()\n\n    >>> # Initializing a model (with random weights) from the google-bert/bert-base-uncased style configuration\n    >>> model = BertModel(configuration)\n\n    >>> # Accessing the model configuration\n    >>> configuration = model.config\n    ```\"\"\"\n\n    model_type = \"bert\"   # 指定模型类型\n\n    def __init__(\n        self,\n        vocab_size=30522, # 词表大小\n        hidden_size=768, # 模型隐藏维度\n        num_hidden_layers=12, # 层数\n        num_attention_heads=12, # 头数\n        intermediate_size=3072,  # 前馈层维度\n        hidden_act=\"gelu\", # 激活函数，支持字符串或函数\n        hidden_dropout_prob=0.1,  # 全连接层的 dropout 概率\n        attention_probs_dropout_prob=0.1,  # 注意力权重的 dropout 概率\n        max_position_embeddings=512,  # 支持的最大序列长度\n        type_vocab_size=2, # token_type_ids 的词表大小\n        initializer_range=0.02, # 权重初始化的标准差\n        layer_norm_eps=1e-12,  # LayerNorm 中避免除零的小常数 epsilon\n        pad_token_id=0, # 填充token id\n        position_embedding_type=\"absolute\",  # 位置编码类型，支持 absolute / relative_key / relative_key_query\n        use_cache=True, # 推理时是否使用缓存past_key_value\n        classifier_dropout=None, # 分类器前的 dropout 概率\n        **kwargs,\n    ):\n        super().__init__(pad_token_id=pad_token_id, **kwargs) # 调用父类的初始化\n\n        self.vocab_size = vocab_size\n        self.hidden_size = hidden_size\n        self.num_hidden_layers = num_hidden_layers\n        self.num_attention_heads = num_attention_heads\n        self.hidden_act = hidden_act\n        self.intermediate_size = intermediate_size\n        self.hidden_dropout_prob = hidden_dropout_prob\n        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n        self.max_position_embeddings = max_position_embeddings\n        self.type_vocab_size = type_vocab_size\n        self.initializer_range = initializer_range\n        self.layer_norm_eps = layer_norm_eps\n        self.position_embedding_type = position_embedding_type\n        self.use_cache = use_cache\n        self.classifier_dropout = classifier_dropout","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:15:49.148018Z","iopub.execute_input":"2025-05-28T09:15:49.148361Z","iopub.status.idle":"2025-05-28T09:15:49.156206Z","shell.execute_reply.started":"2025-05-28T09:15:49.148341Z","shell.execute_reply":"2025-05-28T09:15:49.155019Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"config = BertConfig()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:16:31.256632Z","iopub.execute_input":"2025-05-28T09:16:31.257198Z","iopub.status.idle":"2025-05-28T09:16:31.260716Z","shell.execute_reply.started":"2025-05-28T09:16:31.257174Z","shell.execute_reply":"2025-05-28T09:16:31.260096Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:16:45.431928Z","iopub.execute_input":"2025-05-28T09:16:45.432668Z","iopub.status.idle":"2025-05-28T09:16:45.437641Z","shell.execute_reply.started":"2025-05-28T09:16:45.432641Z","shell.execute_reply":"2025-05-28T09:16:45.437095Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"BertConfig {\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.51.3\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"  # 继承自 OnnxConfig，用于配置 Bert 模型的 ONNX 导出设置\nclass BertOnnxConfig(OnnxConfig):\n    # 这种装饰器叫做 @property 属性装饰器，它将一个方法转化为一个只读属性，可以像访问属性一样访问方法的返回值。\n    # 如需设置或删除该属性，还可以配合 @xxx.setter 和 @xxx.deleter 使用。\n    # @property 装饰后的方法变成的是实例属性\n    @property \n    def inputs(self) -> Mapping[str, Mapping[int, str]]:\n        if self.task == \"multiple-choice\": # 如果是多选任务\n            # 动态轴 0:批次维度,1:多选维度,2:序列维度\n            dynamic_axis = {0: \"batch\", 1: \"choice\", 2: \"sequence\"}\n        else: # 其他任务只有批次和序列维度\n            dynamic_axis = {0: \"batch\", 1: \"sequence\"}\n        return OrderedDict( # 返回输入字典，映射每个输入到对应的动态轴\n            [\n                (\"input_ids\", dynamic_axis),  # 输入 token id\n                (\"attention_mask\", dynamic_axis), # 注意力掩码\n                (\"token_type_ids\", dynamic_axis), # token 类型 ID（用于区分句子对）\n            ]\n        )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:28:09.597786Z","iopub.execute_input":"2025-05-28T09:28:09.598027Z","iopub.status.idle":"2025-05-28T09:28:09.603021Z","shell.execute_reply.started":"2025-05-28T09:28:09.598011Z","shell.execute_reply":"2025-05-28T09:28:09.602290Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"onnxConfig=BertOnnxConfig(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:28:13.664216Z","iopub.execute_input":"2025-05-28T09:28:13.664467Z","iopub.status.idle":"2025-05-28T09:28:13.667921Z","shell.execute_reply.started":"2025-05-28T09:28:13.664448Z","shell.execute_reply":"2025-05-28T09:28:13.667278Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"onnxConfig.task","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:28:14.696785Z","iopub.execute_input":"2025-05-28T09:28:14.697411Z","iopub.status.idle":"2025-05-28T09:28:14.701449Z","shell.execute_reply.started":"2025-05-28T09:28:14.697389Z","shell.execute_reply":"2025-05-28T09:28:14.700832Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'default'"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"onnxConfig.inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T09:28:15.531530Z","iopub.execute_input":"2025-05-28T09:28:15.531800Z","iopub.status.idle":"2025-05-28T09:28:15.536928Z","shell.execute_reply.started":"2025-05-28T09:28:15.531779Z","shell.execute_reply":"2025-05-28T09:28:15.536252Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"OrderedDict([('input_ids', {0: 'batch', 1: 'sequence'}),\n             ('attention_mask', {0: 'batch', 1: 'sequence'}),\n             ('token_type_ids', {0: 'batch', 1: 'sequence'})])"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"__all__ = [\"BertConfig\", \"BertOnnxConfig\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}